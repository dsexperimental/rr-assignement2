---
title: "Human and Economic Costs by Storm Type"
author: "Dave Sutter"
date: "2022-11-16"
output: html_document
---

# NOTES
 - Add the text!
 - I currently show my results for the complete set of data. I should give an
 average per year.
 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(lubridate)
library(stringr)
library(jsonlite)
```

# Synopsis

We examine the storm data file provided by the United States National Weather 
Service to find the storm types that do the most total yearly damage in terms
of fatalities, injuries and dollar damage.

The storm data file includes storm events from 1950 until 2011, in the version 
of the data used. We limited the data used to 1996 and later since the data 
after that point is more complete and is more standardized. 

Even for this range, the type labeling for the data is inconsistent. The main 
task in analyzing the file is interpreting the storm type. We used an 
analysis to map the event type labels in the data set to the official storm
type names used by the National Weather Service.

We then summed the total fatalities, injuries and damage costs for each type and 
averaged to estimate the yearly amounts.

The storm type with the highest average yearly fatalities is "Excessive Heat", 
injuries is "Tornado", and dollar damage is "Flood".

# Data Processing

we take data and process it.

## Utility Functions

The following are some simple functions that are used in the analysis.

``` {r}
##=====================================
## This function converts exponent strings to numerica exponents
##=====================================
## This converts exponent string values that are
## - a number of metric exponents - see code for selection
## - numeric strings (convert to numeric)
## - other - anything else is converted to an exponent of 0
## In addition a safety text is done that there are no single letter
## values that are not converted by the metric coefficients, with the
## assumption that theis coefficient should be added.
convertExpCol <- function(expStr) {
  expNum <- numeric(length(expStr))
  expNum <- NA
  
  expNum[str_detect(expStr,"[hH]")] = 2
  expNum[str_detect(expStr,"[kK]")] = 3
  expNum[str_detect(expStr,"[mM]")] = 6
  expNum[str_detect(expStr,"[bB]")] = 9
  expNum[str_detect(expStr,"[tT]")] = 12
  
  isnum <- str_detect(expStr,"[0-9]+")
  expNum[isnum] = as.numeric(expStr[isnum])
  
  ## SAFETY TEST --------
  ## Check for any remaining single letter exponents
  ## These are probably metric prefixes we left out
  singleLetterExpLeft <- sum(str_detect(expStr[is.na(expNum)],"[a-zA-Z]"))
  if(singleLetterExpLeft > 0) {
    warning("There are unaccounted letter values for exponent! Investigate")
  }
  ##--------------
  
  expNum[is.na(expNum)] = 0 
  
  expNum
}

## standardize string - lowercase and replace dash with space
stdString <- function(textVector) {
  str_replace(tolower(textVector),"-"," ")
}


## this function takes a vector of outerStrings and innerStrings and returns a matrix
## telling if a given outerString contains a given innerString. The outerStrings represent
## row indices and the innerStrings represent column indices
getContainedIn <- function(outerStrings,innerStrings) {
  inner_in_outer <- matrix(FALSE,nrow = length(outerStrings),ncol = length(innerStrings))
  dimnames(inner_in_outer) <- list(outerStrings,innerStrings)
  
  setRow <- function(outerString) {
    inner_in_outer[outerString,] <<- str_detect(outerString,regex(innerStrings,ignore_case=TRUE))
  }
  
  sapply(outerStrings,setRow)
  
  inner_in_outer
}
```

## Loading Data

Here we read in the data from the NWS storm data file. 

``` {r}


## This is a list of column names for the data
colNames <- c("STATE__", "BGN_DATE", "BGN_TIME", "TIME_ZONE", "COUNTY", 
              "COUNTYNAME", "STATE", "EVTYPE", "BGN_RANGE", "BGN_AZI",
              "BGN_LOCATI", "END_DATE", "END_TIME", "COUNTY_END", "COUNTYENDN", 
              "END_RANGE", "END_AZI", "END_LOCATI", "LENGTH", "WIDTH", "F",
              "MAG", "FATALITIES", "INJURIES", "PROPDMG", "PROPDMGEXP", 
              "CROPDMG", "CROPDMGEXP", "WFO", "STATEOFFIC", "ZONENAMES", 
              "LATITUDE", "LONGITUDE", "LATITUDE_E", "LONGITUDE_", "REMARKS",
              "REFNUM") 

## place the column names you want to keep here
colToKeep <- c("BGN_DATE","EVTYPE","FATALITIES","INJURIES","PROPDMG",
               "PROPDMGEXP","CROPDMG","CROPDMGEXP","REMARKS")

## place the column classes here, to help loading
colToKeepClasses <- c("character","character","numeric","numeric","numeric",
                      "character","numeric","character","character")

## generate the col class vector
colClasses <- rep("NULL",length(colNames))
colClasses[match(colToKeep,colNames)] <- colToKeepClasses

## load the csv file
dat <- read.csv("repdata_data_StormData.csv.bz2",colClasses = colClasses)

## SAFETY TEST: verify the format is as expected
if(!identical(colToKeep,names(dat))) {
  error("File not loaded properly! Format may have changed since origianl analysis")
}

```

Here we preprocess the storm data to get it in the desired form to start our analysis.

``` {r}

## convert time from character class
dat$BGN_DATE <- mdy_hms(dat$BGN_DATE)

## we will only use data from 1996 and newer
dat <- filter(dat,BGN_DATE >= "1996-01-01")

## the analysis only examines data that contains damage, fatalities or injuries
dat <- filter(dat,((PROPDMG > 0) | (CROPDMG > 0) | (FATALITIES > 0) | (INJURIES > 0)) )

## standardize the format of the type labels
dat$EVTYPE <- stdString(dat$EVTYPE)

## add a column for damage amounts
## first convert character "exponent" columns to numerical values
dat$PEXP <- convertExpCol(dat$PROPDMGEXP)
dat$CEXP <- convertExpCol(dat$CROPDMGEXP)
dat$DMG <- dat$PROPDMG * (10^dat$PEXP) + dat$CROPDMG * (10^dat$CEXP)

```

Here we load a file containing the official storm types from the NWS. 

This file adn be downloaded from ... However, it can also be generated from
this code...

``` {r}
## official types from NWS
officialTypes <- fromJSON("officialTypes.json")

## convert the official types to the working format: lowercase, "-" removed
types <- stdString(officialTypes)
```

Here we load a "storm alias" file. It includes non-official names which may have
been used to express the storm type.

``` {r}

## type aliases
## - list names: NWS types
## - list values: aliases for these types 
typeAliases <- fromJSON("typeAliases.json")

## invert mapping to go from aliases to types
aliasToType <- list()
addTypeAlias <- function(type,aliases) {
  aliasToType[aliases] <<- type
}
dummy <- mapply(addTypeAlias,names(typeAliases),typeAliases,SIMPLIFY=FALSE)

##this is a vector with the aliases in it
aliases <- names(aliasToType)

## keywords - a list of types and aliases we will use to identify type from labels
keywords <- c(types,aliases)

##create mapping from keywords to types, to identify types from matched keywords
typeToType <- as.list(types)
names(typeToType) <- types
keywordToType <- c(typeToType,aliasToType)
```

## Cleaning the Storm Type Labels

The type label for each event is often not one of the official storm types. 
Here we attempt to standardize the event types.

DESCRIBE HERE

``` {r}

##vector of labels from data set
labels <- unique(dat$EVTYPE)

## k_in_l: logical matrix with an entry TRUE telling if a key (column index) is
## in a label (row index)
k_in_l <- getContainedIn(labels,keywords)

## k_in_k: logical matrix with an entry TRUE telling if a keyword (column index) is
## contained in a keyword (row index)
k_in_k <- getContainedIn(keywords,keywords)

## adj_k_in_k: this is the same as k_in_k except we remove the diagonal entries
## which say a key contains itself
adj_k_in_K <- k_in_k
diag(adj_k_in_K) <- FALSE

## if a longer key contains a shorter key, any label that contains a longer
## key will also contain the shorter key. We want to discard the shorter key
## in this case. The equation below does this. Explanation:
## - k_in_l[label,long key] * adj_k_in_k[long key,short key]: This is true if
##   both a ("long") key contains a ("short") key and a label contains the 
##   ("long") key.
## - (k_in_l %*% adj_k_in_k): for a given label and key, this is true if any
##   other keys both contain this key and are contained in this label
## - k_in_l & !as.logical(k_in_l %*% adj_k_in_K): For any long key that is
##   contained in a label, this clears the flag that states on "short" key contained
##   in this "long" key is also contained in the label
fixed_k_in_l <- k_in_l & !as.logical(k_in_l %*% adj_k_in_K)


##get the list of keywords in each label
getKeywords <- function(innerKeyFlags) {
  keywords[innerKeyFlags]
}
labelKeywords <- apply(fixed_k_in_l,1,getKeywords)

## Here we make a map from the labels to the type
## - if the label contains one keyword (type or alias), we associate it with that type
## - if the label contains multiple keywords (type or alias), we associate it with
##   the fist keyword, with the idea the more damaging factor may likely be placed first. 
##   (alternately other weightings could be attemted)
## - it the label contains 0 or multiple keywords, we record the type as the 
## value of the label enclosed in double arrows, to flag a failed match.
getKeywordTypes <- function(keywords,label) {
  if(length(keywords) > 0) {
    type <- keywordToType[[keywords[1]]]
  }
  else {
    type <- sprintf("<<%s>>",label)
  }
  type
}
labelToType <- mapply(getKeywordTypes,labelKeywords,label=names(labelKeywords),SIMPLIFY=FALSE)


## we use our label to Type mapping to add a "type" column to our data.
## this will either include a valid type name or the label enclosed in "<<" + ">>"
dat$type <- factor(unlist(labelToType[dat$EVTYPE]))
```

# Data Analysis
INTRO?

Here we calculate the total costs for all storms in this period.

SPECIFY THE PERIOD!!!

``` {r}
##===============================
## Get the total costs, fatalities and injuries
##===============================

## get totals
totalCost <- sum(dat$DMG)
totalFatalities <- sum(dat$FATALITIES)
totalInjuries <- sum(dat$INJURIES)
```

Here we create a data frame each for fatalities, injuries and damage cost in 
dollars. Each one contains the value for each type, ordered from maximum to
minimum, and the number of events.

NOTE - THIS IS FOR THE TOTAL PERIOD!

``` {r}

## group the data by type
groupedDat <- dat %>% group_by(type)

## for each category (fatalities, injuries and damage), create a ordered
## data frame of totals by type

fatalitiesDat <- groupedDat %>% 
  summarise(fatalities = sum(FATALITIES),count = length(FATALITIES)) %>% 
  arrange(desc(fatalities))

injuriesDat <- groupedDat %>% 
  summarise(injuries = sum(INJURIES),count = length(INJURIES)) %>% 
  arrange(desc(injuries))

costDat <- groupedDat %>% 
  summarise(cost = sum(DMG),count = length(DMG)) %>% 
  arrange(desc(cost))
```


## Preprocessing of Results Data for Plots

Here we do some preprocessing of the data to prepare it for plotting.

``` {r}
##=================================
## Preprocessing for plotting
##=================================

## this function takes a data frame with three columns
## type (factor), value, count
## it removes all rows that are smaller than a given fraction and replaces these
## with an "other" row
## NOTE: there should not be an existing category named "other"
addOtherCat <- function(fullDF,cutoffFrac) {
  #truncate the data frame
  totalValue <- sum(fullDF[[2]])
  totalCount <- sum(fullDF[[3]])
  redDF <- filter(fullDF,fullDF[[2]] / totalValue >= cutOffFrac)
  
  ##get the "other" value and count and append it
  otherValue <- totalValue - sum(redDF[[2]])
  otherCount <- totalCount - sum(redDF[[3]])
  levels(redDF[[1]]) <- c(levels(redDF[[1]]),"other")
  newRow <- list("other",otherValue,otherCount)
  names(newRow) <- names(redDF)
  redDF[length(redDF[[1]]) + 1,] <- newRow
  redDF
}

##this is the fractional value below which we wil place in the "other" type
cutOffFrac <- 0.007

## color palette
pal <- colorRampPalette(palette.colors(n=8,palette = "Pastel 2"))
otherColor <- rgb(230,230,230,maxColorValue=255)

# create modified data frames keeping only the major types
## which are data readable from the pie chart
redCostDat <- addOtherCat(costDat,cutOffFrac)
redFatalitiesDat <- addOtherCat(fatalitiesDat,cutOffFrac)
redInjuriesDat <- addOtherCat(injuriesDat,cutOffFrac)
```


# Results

## Fatalities

Here we show a plot of the storm types with the highest number of fatalities.

``` {r, fig.height=6,fig.width=7}
pie(redFatalitiesDat$fatalities,
    labels=sprintf("%s (%.0d)",redFatalitiesDat$type,redFatalitiesDat$fatalities),
    cex=0.6,init.angle=20,col=c(pal(length(redFatalitiesDat$type)-1),otherColor),
    main="Fatalities by Storm Type",
    sub = sprintf("Total Fatalities: %.0d",totalFatalities))
```

## Injuries

Here we show a plot of the storm types with the highest number of injuries.

``` {r, fig.height=6,fig.width=7}
pie(redInjuriesDat$injuries,
    labels=sprintf("%s (%.0d)",redInjuriesDat$type,redInjuriesDat$injuries),
    cex=0.75,init.angle=20,col=c(pal(length(redInjuriesDat$type)-1),otherColor),
    main="Injuries by Storm Type",
    sub = sprintf("Total Injuries: %.0d",totalInjuries))
```

## Damage Cost in Dollars

Here we show a plot of the storm types with the greatest cost of damge.

``` {r, fig.height=6,fig.width=7}
pie(redCostDat$cost,
    labels=sprintf("%s $%.1fB",redCostDat$type,redCostDat$cost/1000000000),
    cex=0.75,init.angle=20,col=c(pal(length(redCostDat$type)-1),otherColor),
    main="Dollar Cost by Storm Type",
    sub = sprintf("Total Cost: $%.1fB",totalCost/1000000000))
```

# Supplemental Data

INTRO?

## Fatalities by Storm Type

Here we present the complete table of fatalities by storm type.

``` {r}
## complete fatalities table
print(fatalitiesDat,n=length(fatalitiesDat$type))
```

## Injuries by Storm Type

Here we present the complete table of injuries by storm type.

``` {r}
## complete injuries table
print(injuriesDat,n=length(injuriesDat$type))
```

## Damage Costs by Storm Type

Here we present the complete table of damage costs by storm type.

``` {r}
## complete cost table
print(costDat,n=length(costDat$type))
```

## Keyword Matching Analysis

DISCUSSION OF KEYWORD MATCHING

Here we calculate a vector of keyword matching counts for each type label from
the storm data file.

``` {r}
## this is the count for a given label keyword
labelKeywordCounts <- sapply(labelKeywords,length)
```

### Labels with no Keyword Matches

``` {r}
## labels with no keyword matches
names(labelKeywords[labelKeywordCounts == 0])
```

### Labels with One Keyword Match

``` {r}
## labels with 1 keyword match
names(labelKeywords[labelKeywordCounts == 1])
```

### Labels with Two Keyword Matches

``` {r}
## labels with 2 keyword matches
names(labelKeywords[labelKeywordCounts == 2])
```

### Labels with Three or More Keyword Matches

``` {r}
## labels with 3 or more keyword matches
names(labelKeywords[labelKeywordCounts >= 3])
```

## Data Files

NOTES ABOUT THE DATA FILES

### NWS Storm Types

TALK ABOUT THIS

Here is a list of the official storm types.

``` {r}

##NWS types, as listed from NWS
print(officialTypes)

```

Here is a function that can be used to generate the storm type file and
save it in the location used by this document.

``` {r}
## This function creates the official types data file and places it in
## the location used by this analysis.
generateStormTypeFile <- function() {
  typeJson <- '["Tsunami", "Storm Surge/Tide", "High Surf", "Seiche", 
                "Rip Current", "Astronomical Low Tide", "Flash Flood", "Flood", 
                "Coastal Flood", "Lakeshore Flood", "Heavy Rain", "Hail", 
                "Lightning", "Hurricane (Typhoon)", "Tropical Depression", 
                "Tropical Storm", "Thunderstorm Wind", "High Wind", "Strong Wind", 
                "Dust Storm", "Tornado", "Funnel Cloud", "Waterspout", 
                "Dust Devil", "Blizzard", "Winter Storm", "Heavy Snow", 
                "Ice Storm", "Lake-Effect Snow", "Sleet", "Winter Weather", 
                "Avalanche", "Extreme Cold/Wind Chill", "Frost/Freeze", 
                "Cold/Wind Chill", "Excessive Heat", "Heat", "Dense Fog", 
                "Freezing Fog", "Debris Flow", "Wildfire", "Dense Smoke", 
                "Drought", "Volcanic Ash", "Marine Hail", "Marine High Wind", 
                "Marine Strong Wind", "Marine Thunderstorm Wind"]'
  
  writeLines(typeJson,"officialTypes.json")
}
```

### Storm Type Aliases

TALK ABOUT THIS

Here is a list of the storm type aliases used in this analysis.

``` {r}
print(typeAliases)
```

Here is a function that can be used to generate the type aliases file and
save it in the location used by this document.

``` {r}
## This function creates the type alias data file and places it in
## the location used by this analysis.
generateTypeAliasFile <- function() {
  typeAliasJson <- '{
  "cold/wind chill": ["cold", "wind chill", "windchill", "hypothermia/exposure", "hyperthermia/exposure"],
  "debris flow": ["landslide", "rock slide", "mud slide", "mudslide", "landslump"],
  "dense fog": ["fog"],
  "dust storm": ["blowing dust"],
  "extreme cold/wind chill": ["extreme cold", "extreme wind chill", "extreme windchill"],
  "freezing fog": ["glaze"],
  "frost/freeze": ["frost", "freeze", "black ice"],
  "flood": ["dam break"],
  "flash flood": ["flash flood/flood", "flood/flash/flood"],
  "heat": ["unseasonably warm", "warm weather"],
  "heavy rain": ["torrential rainfall", "urban/sml stream fld", "hvy rain", "rain", "unseasonal rain"],
  "heavy snow": ["excessive snow"],
  "high surf": ["heavy surf", "rough surf", "hazardous surf"],
  "high wind": ["non tstm wind", "non-tstm wind"],
  "hurricane (typhoon)": ["hurricane", "typhoon", "hurricane/typhoon"],
  "lake-effect snow": ["lake effect snow"],
  "storm surge/tide": ["storm surge"],
  "strong wind": ["gusty wind", "gradient wind", "wind damage", "wind"],
  "thunderstorm wind": ["tstm wind", "tstmw", "gustnado", "downburst", "microburst"],
  "tornado": ["landspout"],
  "wildfire": ["wild fire", "grass fire", "forest fire", "brush fire"],
  "winter weather": ["freezing rain", "light snowfall", "snow and ice", "late season snow", "light snow", "snow", "freezing drizzle", "rain/snow", "snow squall", "mixed precipitation", "blowing snow", "wintry mix", "mixed precip", "snow squalls", "falling snow/ice", "cold and snow", "ice roads", "icy roads", "ice on roads"]
}'
  writeLines(typeAliasJson,"typeAliases.json")
}
```